{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, GlobalMaxPooling1D\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import\n",
    "data = pd.read_csv('Data/balenced_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Labels: ['abstract' 'article' 'blog' 'movie' 'reddit' 'song' 'twitter']\n",
      "Missing values for abstract: text      0\n",
      "Source    0\n",
      "dtype: int64\n",
      "Missing values for article: text      0\n",
      "Source    0\n",
      "dtype: int64\n",
      "Missing values for blog: text      0\n",
      "Source    0\n",
      "dtype: int64\n",
      "Missing values for movie: text      585\n",
      "Source      0\n",
      "dtype: int64\n",
      "Missing values for reddit: text      11\n",
      "Source     0\n",
      "dtype: int64\n",
      "Missing values for song: text      0\n",
      "Source    0\n",
      "dtype: int64\n",
      "Missing values for twitter: text      0\n",
      "Source    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique_labels = data['Source'].unique()\n",
    "print(\"Unique Labels:\", unique_labels)\n",
    "for label in unique_labels:\n",
    "    na_count = data[data['Source'] == label].isna().sum()\n",
    "    print(f\"Missing values for {label}:\", na_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    # Handle missing values in text data\n",
    "    data['text'].fillna(\"\", inplace=True)\n",
    "\n",
    "    text_data = data['text'].tolist()\n",
    "    target = data['Source']\n",
    "\n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_text = [' '.join([stemmer.stem(word) for word in text.split()]) for text in text_data]\n",
    "\n",
    "    # TF-IDF vectorization\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(stemmed_text)\n",
    "\n",
    "    # Step 3: Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, vectorizer\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21968, 225833) (21968,)\n",
      "(5493, 225833) (5493,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, vectorizer = preprocess_data(data)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinominalNB als Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7302249715975466\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    abstract       0.99      1.00      0.99       777\n",
      "     article       0.63      0.93      0.75       790\n",
      "        blog       0.86      0.22      0.35       811\n",
      "       movie       0.33      0.85      0.48       805\n",
      "      reddit       0.52      0.23      0.32       759\n",
      "        song       0.91      0.33      0.48       769\n",
      "     twitter       0.88      0.73      0.80       782\n",
      "\n",
      "    accuracy                           0.61      5493\n",
      "   macro avg       0.73      0.61      0.60      5493\n",
      "weighted avg       0.73      0.61      0.60      5493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Multinomial Naive Bayes classifier\n",
    "classifiermultib = MultinomialNB()\n",
    "# Train the classifier\n",
    "classifiermultib.fit(X_train, y_train)\n",
    "# Example usage\n",
    "# Make predictions on the test data\n",
    "y_pred_multib = classifiermultib.predict(X_test)\n",
    "# Evaluate the classifier\n",
    "precision_multib = precision_score(y_test, y_pred_multib, average='weighted')\n",
    "report_multib = classification_report(y_test, y_pred_multib)\n",
    "print(\"Precision:\", precision_multib)\n",
    "print(\"Classification Report:\")\n",
    "print(report_multib)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9306422565987887\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    abstract       1.00      1.00      1.00       777\n",
      "     article       0.95      0.95      0.95       790\n",
      "        blog       0.91      0.84      0.87       811\n",
      "       movie       0.98      0.99      0.99       805\n",
      "      reddit       0.78      0.92      0.85       759\n",
      "        song       0.95      0.89      0.92       769\n",
      "     twitter       0.94      0.89      0.91       782\n",
      "\n",
      "    accuracy                           0.93      5493\n",
      "   macro avg       0.93      0.93      0.93      5493\n",
      "weighted avg       0.93      0.93      0.93      5493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an SVM classifier\n",
    "classifier_SVM = SVC()\n",
    "# Train the classifier\n",
    "classifier_SVM.fit(X_train, y_train)\n",
    "# Make predictions on the test data\n",
    "y_pred_SVM = classifier_SVM.predict(X_test)\n",
    "# Evaluate the classifier\n",
    "precision_SVM = precision_score(y_test, y_pred_SVM, average='weighted')\n",
    "report_SVM = classification_report(y_test, y_pred_SVM)\n",
    "print(\"Precision:\", precision_SVM)\n",
    "print(\"Classification Report:\")\n",
    "print(report_SVM)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.905625941361713\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    abstract       1.00      1.00      1.00       777\n",
      "     article       0.91      0.95      0.93       790\n",
      "        blog       0.85      0.83      0.84       811\n",
      "       movie       0.87      1.00      0.93       805\n",
      "      reddit       0.85      0.78      0.81       759\n",
      "        song       0.95      0.85      0.90       769\n",
      "     twitter       0.91      0.92      0.92       782\n",
      "\n",
      "    accuracy                           0.90      5493\n",
      "   macro avg       0.91      0.90      0.90      5493\n",
      "weighted avg       0.91      0.90      0.90      5493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest classifier\n",
    "classifierRF = RandomForestClassifier()\n",
    "# Train the classifier\n",
    "classifierRF.fit(X_train, y_train)\n",
    "# Make predictions on the test data\n",
    "y_pred_RF = classifierRF.predict(X_test)\n",
    "# Evaluate the classifier\n",
    "precision_RF = precision_score(y_test, y_pred_RF, average='weighted')\n",
    "report_RF = classification_report(y_test, y_pred_RF)\n",
    "print(\"Precision:\", precision_RF)\n",
    "print(\"Classification Report:\")\n",
    "print(report_RF)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Gradient Boosting classifier\n",
    "classifierGB = GradientBoostingClassifier()\n",
    "# Train the classifier\n",
    "classifierGB.fit(X_train, y_train)\n",
    "# Make predictions on the test data\n",
    "y_pred_GB = classifierGB.predict(X_test)\n",
    "# Evaluate the classifier\n",
    "precision_GB = precision_score(y_test, y_pred_GB, average='weighted')\n",
    "report_GB = classification_report(y_test, y_pred_GB)\n",
    "print(\"Precision:\", precision_GB)\n",
    "print(\"Classification Report:\")\n",
    "print(report_GB)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9154214893941176\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    abstract       1.00      1.00      1.00       777\n",
      "     article       0.94      0.96      0.95       790\n",
      "        blog       0.91      0.85      0.88       811\n",
      "       movie       0.96      0.84      0.90       805\n",
      "      reddit       0.70      0.93      0.80       759\n",
      "        song       0.95      0.87      0.91       769\n",
      "     twitter       0.94      0.88      0.91       782\n",
      "\n",
      "    accuracy                           0.90      5493\n",
      "   macro avg       0.91      0.91      0.91      5493\n",
      "weighted avg       0.92      0.90      0.91      5493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Model selection and training\n",
    "classifierLR = LogisticRegression()\n",
    "classifierLR.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Model evaluation\n",
    "y_pred_LR = classifierLR.predict(X_test)\n",
    "precision_LR = precision_score(y_test, y_pred_LR, average='weighted')\n",
    "report_LR = classification_report(y_test, y_pred_LR)\n",
    "print(\"Precision:\", precision_LR)\n",
    "print(\"Classification Report:\")\n",
    "print(report_LR)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensambling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create individual models\n",
    "model1 = MultinomialNB()\n",
    "model2 = RandomForestClassifier()\n",
    "model3 = GradientBoostingClassifier()\n",
    "model4 = SVC(probability=True)  # SVM model\n",
    "\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "    ('nb', model1),\n",
    "    ('rf', model2),\n",
    "    ('gb', model3),\n",
    "    ('svm', model4),\n",
    "    ('nn', model5)\n",
    "], voting='soft')\n",
    "\n",
    "# Train the voting classifier\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "# Make predictions on the test data\n",
    "y_pred = voting_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the voting classifier\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def preprocess_data(data):\n",
    "    # Handle missing values in text data\n",
    "    data['text'].fillna(\"\", inplace=True)\n",
    "\n",
    "    # Perform stemming using PorterStemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    data['text'] = data['text'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n",
    "\n",
    "    text_data = data['text'].tolist()\n",
    "    target = data['Source']\n",
    "\n",
    "    return text_data, target\n",
    "\n",
    "# Load and preprocess the data\n",
    "text_data, target = preprocess_data(data)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_data, target, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "models = [\n",
    "    ('Multinomial Naive Bayes', MultinomialNB()),\n",
    "    ('SVM', SVC()),\n",
    "    ('Random Forest', RandomForestClassifier()),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier()),\n",
    "    ('Logistic Regression', LogisticRegression())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;model&#x27;,\n",
       "                 [(&#x27;Multinomial Naive Bayes&#x27;, MultinomialNB()), (&#x27;SVM&#x27;, SVC()),\n",
       "                  (&#x27;Random Forest&#x27;, RandomForestClassifier()),\n",
       "                  (&#x27;Gradient Boosting&#x27;, GradientBoostingClassifier()),\n",
       "                  (&#x27;Logistic Regression&#x27;, LogisticRegression())])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;model&#x27;,\n",
       "                 [(&#x27;Multinomial Naive Bayes&#x27;, MultinomialNB()), (&#x27;SVM&#x27;, SVC()),\n",
       "                  (&#x27;Random Forest&#x27;, RandomForestClassifier()),\n",
       "                  (&#x27;Gradient Boosting&#x27;, GradientBoostingClassifier()),\n",
       "                  (&#x27;Logistic Regression&#x27;, LogisticRegression())])])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">list</label><div class=\"sk-toggleable__content\"><pre>[(&#x27;Multinomial Naive Bayes&#x27;, MultinomialNB()), (&#x27;SVM&#x27;, SVC()), (&#x27;Random Forest&#x27;, RandomForestClassifier()), (&#x27;Gradient Boosting&#x27;, GradientBoostingClassifier()), (&#x27;Logistic Regression&#x27;, LogisticRegression())]</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('model',\n",
       "                 [('Multinomial Naive Bayes', MultinomialNB()), ('SVM', SVC()),\n",
       "                  ('Random Forest', RandomForestClassifier()),\n",
       "                  ('Gradient Boosting', GradientBoostingClassifier()),\n",
       "                  ('Logistic Regression', LogisticRegression())])])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('model', models)\n",
    "])\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the individual models\n",
    "for name, model in models:\n",
    "    print(\"Training:\", name)\n",
    "    pipeline.set_params(model=model)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    accuracy = pipeline.score(X_test, y_test)\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
